{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bdb1e61b-5905-477e-a83c-82cfd1f5c729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time import time\n",
    "from helper import *\n",
    "from models import *\n",
    "from cleaning import *\n",
    "import fasttext.util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e562b210-35f1-4313-b40b-73a650c8d9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_set Info: SIZE= 157576, POSITIVE Tweets =49.71%, NEGATIVE Tweets = 50.29%\n",
      "Test_set Info: SIZE= 39394, POSITIVE Tweets =49.69%, NEGATIVE Tweets = 50.31%\n"
     ]
    }
   ],
   "source": [
    "pos_train , neg_train = load_data()\n",
    "#pos_train = pos_train.iloc[:2000]\n",
    "#neg_train = neg_train.iloc[:2000]\n",
    "X_train, X_test, y_train, y_test = split_data(pos_train, neg_train) #return pandas series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ce8599d5-b952-4d37-b86a-13b7cc52945d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 5s, sys: 20.1 s, total: 2min 25s\n",
      "Wall time: 2min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# CELL : avec SVM clean + Train = 15min pour 80.000 train set \n",
    "#clean  \n",
    "X_train_clean= X_train.apply(clean_tweet)\n",
    "X_test_clean = X_test.apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c7e5ab21-c601-4f6a-9a67-ab6a40228106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72642                         user exclamation sure good x\n",
       "14644                                         user sup hun\n",
       "83188    bestfriend love person make truly happy glad c...\n",
       "69015                        user hey follow back question\n",
       "60361    user dont like playing game unless ive played ...\n",
       "                               ...                        \n",
       "69964    laugh lost work exclamation fucking school com...\n",
       "25324             luvlaughstein user stuff came mail today\n",
       "65689                          user user user mag question\n",
       "66804                               im reaching find youre\n",
       "80450    someone named eva hardcover night nazi soldier...\n",
       "Name: Text, Length: 157576, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f06504c-fc1b-4c6b-a4d6-91bd9199b0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train_clean = X_train_clean.to_frame()\n",
    "df_X_test_clean = X_test_clean.to_frame()\n",
    "df_y_train = y_train.to_frame()\n",
    "df_y_test = y_test.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "71ae6072-fa9d-46b0-ac34-90b913daab14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get english word embeddings trained using fasttext\n",
    "## size of word vectors in a hyperparameter cross validation to find best one\n",
    "ft = fasttext.load_model('cc.en.300.bin')\n",
    "ft.get_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "83394fd9-0956-4720-bf39-1f9f85e6564e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ft.get_nearest_neighbors('hello')\n",
    "def get_word_emb(tweet):\n",
    "    avg_vect = np.zeros(300)\n",
    "    for word in tweet:\n",
    "        avg_vect += ft.get_word_vector(word)\n",
    "    return avg_vect / 300\n",
    "\n",
    "tr_set = df_X_train_clean.apply(get_word_emb,axis=1).to_frame()\n",
    "te_set = df_X_test_clean.apply(get_word_emb,axis=1).to_frame()\n",
    "y_tr = df_y_train\n",
    "y_te = df_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1fcd4441-bc18-427b-8842-c1646d1be923",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tr_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/y1/1xm5qj7x01d8m8nrxxsqx5m80000gn/T/ipykernel_30530/1392765034.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_y_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_te\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_y_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tr_set' is not defined"
     ]
    }
   ],
   "source": [
    "y_tr = df_y_train\n",
    "y_te = df_y_test\n",
    "print(tr_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5e289a9f-1c96-4646-a135-5ddce0421c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157576, 300)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors = tr_set[0].to_numpy()\n",
    "corr_array = np.zeros(300)\n",
    "corr_array = corr_array.reshape(300, -1)\n",
    "for index in range(word_vectors.shape[0]):\n",
    "   # print(word_vectors[index])\n",
    "    corr_array = np.c_[corr_array, word_vectors[index]]\n",
    "tr_set_correct = corr_array[:,1:].T\n",
    "tr_set_correct.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "df345d37-4bcd-47af-9513-06a2ccdcb2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_matrix(pandas_dataframe):\n",
    "    word_vectors = pandas_dataframe[0].to_numpy()\n",
    "    corr_array = np.zeros(300)\n",
    "    corr_array = corr_array.reshape(300, -1)\n",
    "    for index in range(word_vectors.shape[0]):\n",
    "        corr_array = np.c_[corr_array, word_vectors[index]]\n",
    "    return corr_array[:,1:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b99786e4-8d4d-4ae1-ba0a-0cb3c764b6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39394, 300)\n"
     ]
    }
   ],
   "source": [
    "te_set_correct = make_matrix(te_set)\n",
    "print(te_set_correct.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5abb10ea-e830-4e15-bfa2-104c1fd686e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157576, 300)\n",
      "(39394, 300)\n"
     ]
    }
   ],
   "source": [
    "# Reading the pickle object\n",
    "file_to_read = open(\"tr_saved.pickle\",\"rb\")\n",
    "tr_set_correct = pickle.load(file_to_read)\n",
    "file_to_read.close()\n",
    "file_to = open(\"te_saved.pickle\",\"rb\")\n",
    "te_set_correct = pickle.load(file_to)\n",
    "file_to.close()\n",
    "print(tr_set_correct.shape)\n",
    "print(te_set_correct.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36360acc-db8d-4f8d-9384-fce94174236b",
   "metadata": {},
   "source": [
    "## Using SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e583085b-96bc-4f9d-9529-09c64ae5fe5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "classifier = svm.SVC()\n",
    "classifier.fit(tr_set_correct, y_tr.to_numpy().reshape(-1))\n",
    "#y_pred = clf.predict(te_set.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf681c5-7d28-43d2-8f64-0a115d308a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(te_set_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbd4a1d-7a73-4596-9181-2a1e85e807ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.52896380159414"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sum(y_pred == y_te.to_numpy().reshape(-1)) / y_pred.shape[0]) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4107c3d6-98ae-4e96-b1fa-dedc55cd164b",
   "metadata": {},
   "source": [
    "## Using Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a4066f50-f1e1-40d8-98db-96644402de2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make predictions in correct format for logistic regression 0,1 instead of -1, 1\n",
    "y_tr_logi =  y_tr.to_numpy().reshape(-1)\n",
    "y_te_logi = y_te.to_numpy().reshape(-1)\n",
    "y_tr_logi[y_tr_logi == -1] = 0\n",
    "y_te_logi[y_te_logi == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f48bfe8f-d526-49a7-b6fe-34427de019d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50.31476874650962"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression().fit(tr_set_correct,  y_tr_logi)\n",
    "y_pred_log = classifier.predict(te_set_correct)\n",
    "print(y_pred_log)\n",
    "(sum(y_pred_log == y_te_logi) / y_pred_log.shape[0]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "455cd0bc-f1ef-4805-82af-3db0609bbb5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_log[y_pred_log==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58a7eb3-81f1-4a93-8c2c-21b4b073dfad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed77dd1e-c08f-4706-beda-0c5f7f180211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "be04410b-4fda-43d6-81da-c0a6d6b48764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the pickle object\n",
    "#file_to_read_test = open(\"tr_saved.pickle\",\"rb\")\n",
    "#pickle_test = pickle.load(file_to_read_test)\n",
    "#file_to_read_test.close()\n",
    "#print(pickle_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4071d9ad-c2dd-4600-bde2-839e7f49a6f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
