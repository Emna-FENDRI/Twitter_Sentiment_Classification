{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "469cdfe1-4ea1-4083-b25f-f9685737b9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed\\anaconda3\\lib\\site-packages\\ekphrasis\\classes\\exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
      "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from helper import *\n",
    "from models import *\n",
    "from cleaning import clean_tweets\n",
    "import nltk\n",
    "import pickle\n",
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
    "from ekphrasis.dicts.emoticons import emoticons\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41cb46ea-7024-45ac-bf3a-3737eeb04ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ahmed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ahmed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ahmed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72a5b4b0-5cfa-4bf7-9509-d41f69296627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n",
      "Found 1193515 word vectors.\n"
     ]
    }
   ],
   "source": [
    "print('Indexing word vectors.')\n",
    "\n",
    "embeddings_index = {}\n",
    "DIM_SIZE = 25\n",
    "f = open('../Data/glove.twitter.27B.25d.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b387402d-68eb-4f92-8ea3-a3c88a3b3d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/preprocessed_embeddings_index.pkl', 'wb') as f:\n",
    "    pickle.dump(embeddings_index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7efe566c-d2e1-4bf8-969f-34c1acb5614a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tweets = []\n",
    "neg_tweets = []\n",
    "with open(\"../Data/twitter-datasets/train_pos_full.txt\",\"r\", encoding = 'utf8') as f:\n",
    "    pos_tweets = f.readlines()\n",
    "    f.close()\n",
    "with open(\"../Data/twitter-datasets/train_neg_full.txt\", \"r\", encoding = 'utf8') as f:\n",
    "    neg_tweets = f.readlines()\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e59f9f14-85d6-405b-b5cf-7d70fdbfec23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed\\anaconda3\\lib\\site-packages\\ekphrasis\\classes\\tokenizer.py:225: FutureWarning: Possible nested set at position 2190\n",
      "  self.tok = re.compile(r\"({})\".format(\"|\".join(pipeline)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8a0fec03bf4a138e69bd1d85d97b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf341cf4827441091c2aff3e56fd1f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c39f2825da345078009f48c77088086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce01d028d3be4e94bba606d93bfd8ca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b775eba8292649f28ec8f01282c1fd72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "673e2e2d7ad74601a094cd1e387d6914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad04c692a5104a7ba76f7e22f034ed60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f973192d030446fcbf69fc735d6839b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_processor = TextPreProcessor(\n",
    "# terms that will be normalized\n",
    "normalize=['url', 'email', 'percent', 'money', 'phone', 'user',\n",
    "    'time', 'url', 'date', 'number'],\n",
    "# terms that will be annotated\n",
    "annotate={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\",\n",
    "    'emphasis', 'censored'},\n",
    "fix_html=True,  # fix HTML tokens\n",
    "\n",
    "# corpus from which the word statistics are going to be used \n",
    "# for word segmentation \n",
    "segmenter=\"twitter\", \n",
    "\n",
    "# corpus from which the word statistics are going to be used \n",
    "# for spell correction\n",
    "corrector=\"twitter\", \n",
    "\n",
    "unpack_hashtags=True,  # perform word segmentation on hashtags\n",
    "unpack_contractions=True,  # Unpack contractions (can't -> can not)\n",
    "spell_correct_elong=True,  # spell correction for elongated words\n",
    "\n",
    "# select a tokenizer. You can use SocialTokenizer, or pass your own\n",
    "# the tokenizer, should take as input a string and return a list of tokens\n",
    "tokenizer=SocialTokenizer(lowercase=True).tokenize,\n",
    "\n",
    "# list of dictionaries, for replacing tokens extracted from the text,\n",
    "# with other expressions. You can pass more than one dictionaries.\n",
    "dicts=[emoticons]\n",
    ")\n",
    "\n",
    "neg_tweets_cleaned = clean_tweets(neg_tweets,text_processor)\n",
    "pos_tweets_cleaned = clean_tweets(pos_tweets,text_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb9a17f6-fe81-42b6-81c5-4a58c59a05e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vinco', 'tresorpack', 'difficulty', 'object', 'disassemble', 'reassemble', 'wooden', 'pieces', 'beautiful', 'wo']\n"
     ]
    }
   ],
   "source": [
    "print(neg_tweets_cleaned[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d990df5-73bf-497e-a47b-494e842a2ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dfe3018edd044f193ed6531a838fa23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\ahmed\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc83e01611ca43e39c997d47d966fbc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffiling and saving training_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "from models import *\n",
    "training_data = []\n",
    "for tweet in tqdm(neg_tweets_cleaned):\n",
    "    emb = Tweet_to_GloVe(tweet,embeddings_index)\n",
    "    training_data.append([np.array(emb), np.array([1.0, 0.0])])\n",
    "\n",
    "for tweet in tqdm(pos_tweets_cleaned):\n",
    "    emb = Tweet_to_GloVe(tweet,embeddings_index)\n",
    "    training_data.append([np.array(emb),np.array([0.0, 1.0])])\n",
    "\n",
    "print(\"Shuffiling and saving training_data\")\n",
    "np.random.shuffle(training_data)\n",
    "np.save(\"training_data.npy\", training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5fd7663-6c48-40ef-b67a-caf3ef83ac52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500000, 2)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84f6e5a9-7f73-458c-bb62-173006f08f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([-0.417597  ,  0.22064498,  0.12767   , -0.331715  , -0.73833501,\n",
       "              -0.3062    ,  1.72120005,  0.84535003, -0.73247002,  0.64841001,\n",
       "              -0.99503499,  0.19454   , -3.72455001, -0.63418499,  0.62081499,\n",
       "              -0.16795501,  0.90075499, -1.06484997, -1.1239    , -0.33067499,\n",
       "               0.24281001, -0.02501   , -0.90321997,  1.45124996, -0.86731499]),\n",
       "       array([0., 1.])], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf87d46-ee8f-4632-a036-7fb5d3163751",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
