{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dee6785b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9d19000",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "124e08d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input():\n",
    "    for fn in ['train_neg_full.txt', 'train_pos_full.txt']:\n",
    "        with open(fn) as f:\n",
    "                for idx, line in enumerate(f):\n",
    "                    yield gensim.utils.simple_preprocess(line)\n",
    "all_tweets = list(read_input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efd380e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(245364813, 311164330)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec (all_tweets, size=150, window=10, min_count=2, workers=10)\n",
    "model.train(all_tweets,total_examples=len(all_tweets),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3724dba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = \"excited\"\n",
    "model.wv.most_similar (positive=w1)\n",
    "len(model.wv['happy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fc4ffd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "neg_tweets = open(\"neg_train.txt\")\n",
    "pos_tweets = open(\"pos_train.txt\")\n",
    "neg_tweets_list = neg_tweets.readlines()\n",
    "pos_tweets_list = pos_tweets.readlines()\n",
    "print(len(neg_tweets_list))\n",
    "print(len(pos_tweets_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1ba8f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def tokenize_tweets(tweets_list):\n",
    "    tweets = []\n",
    "    for t in tweets_list:\n",
    "        tweets.append(word_tokenize(t))\n",
    "    return tweets\n",
    "pos = tokenize_tweets(pos_tweets_list)\n",
    "neg = tokenize_tweets(neg_tweets_list)\n",
    "print(len(pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "531e5157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "x = []\n",
    "y = []\n",
    "for tweet in pos:\n",
    "    avg = np.zeros(150)\n",
    "    for word in tweet:\n",
    "        if word in model.wv:\n",
    "            avg += model.wv[word]\n",
    "    x.append(avg)\n",
    "    y.append(1)\n",
    "for tweet in neg:\n",
    "    avg = np.zeros(150)\n",
    "    for word in tweet:\n",
    "        if word in model.wv:\n",
    "            avg += model.wv[word]\n",
    "    x.append(avg)\n",
    "    y.append(-1)\n",
    "print(len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "576379a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = x[:100000]\n",
    "y_tr = y[:100000]\n",
    "x_te = x[100000:]\n",
    "y_te = y[100000:]\n",
    "#x = x[:50] + x[-50:]\n",
    "#y = y[:50] + y[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5357272c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d6120b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]...............................................................................................................................................................................................................................................................................*....................................................................................................*\n",
      "optimization finished, #iter = 371885\n",
      "obj = -135992.650307, rho = -0.167752\n",
      "nSV = 157629, nBSV = 424\n",
      "Total nSV = 157629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=100, gamma=0.001, verbose=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train using SVM\n",
    "from sklearn import svm\n",
    "\n",
    "classifier = svm.SVC(gamma=0.001, C=100,verbose=1)\n",
    "classifier.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e4909ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"<user> ooohh don't talk about that but no i was at a wedding & wore heels so my feets are dead\"\n",
    "avg = np.zeros(150)\n",
    "for w in word_tokenize(test):\n",
    "    if w in model.wv:\n",
    "        avg += model.wv[w]\n",
    "#print(avg)\n",
    "classifier.predict(avg.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8f71dc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(tweet):\n",
    "    avg = np.zeros(150)\n",
    "    for w in word_tokenize(tweet):\n",
    "        if w in model.wv:\n",
    "            avg += model.wv[w]\n",
    "    return classifier.predict(avg.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5227de47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted tweet at line 0\n",
      "predicted tweet at line 1000\n",
      "predicted tweet at line 2000\n",
      "predicted tweet at line 3000\n",
      "predicted tweet at line 4000\n",
      "predicted tweet at line 5000\n",
      "predicted tweet at line 6000\n",
      "predicted tweet at line 7000\n",
      "predicted tweet at line 8000\n",
      "predicted tweet at line 9000\n"
     ]
    }
   ],
   "source": [
    "## Make predictions using the SVM classifier\n",
    "pred_file = \"pred_svm1.csv\"\n",
    "with open(pred_file, 'w') as out:\n",
    "    with open(\"test_data.txt\") as f:\n",
    "        out.write(\"Id,Prediction\")\n",
    "        for nb ,line in enumerate(f):\n",
    "            id_tweet = line.split(',',1)\n",
    "            tweet_id, tweet = id_tweet[0], id_tweet[1]\n",
    "            pred = make_prediction(tweet)[0]\n",
    "            if nb % 1000 == 0:\n",
    "                print(f\"predicted tweet at line {nb}\")\n",
    "            out.write(f\"{tweet_id},{pred}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61149b18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
