{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed\\anaconda3\\lib\\site-packages\\ekphrasis\\classes\\exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
      "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from time import time\n",
    "from helper import *\n",
    "from models import *\n",
    "from cleaning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_set Info: SIZE= 6400, POSITIVE Tweets =50.09%, NEGATIVE Tweets = 49.91%\n",
      "Test_set Info: SIZE= 1600, POSITIVE Tweets =49.62%, NEGATIVE Tweets = 50.38%\n"
     ]
    }
   ],
   "source": [
    "pos_train , neg_train = load_data(full = True)\n",
    "pos_train = pos_train.iloc[:4000]\n",
    "neg_train = neg_train.iloc[:4000]\n",
    "X_train, X_test, y_train, y_test = split_data(pos_train, neg_train) #return pandas series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records of positive tweets left 3517\n",
      "Records of negative tweets left 3642\n",
      "Wall time: 50 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Drop Duplicates\n",
    "pos_train.drop_duplicates(inplace=True)\n",
    "neg_train.drop_duplicates(inplace=True)\n",
    "print('Records of positive tweets left', len(pos_train))\n",
    "print('Records of negative tweets left', len(neg_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# CELL : avec SVM clean + Train = 15min pour 80.000 train set \n",
    "#clean  \n",
    "X_train_clean= X_train.apply(clean_tweet)\n",
    "X_test_clean = X_test.apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tweet_to_GloVe(tweet,embeddings_index):\n",
    "    tweet_list = tweet.split()\n",
    "    tweet_list_filtered =  list(set(tweet_list) & set(embeddings_index.keys()))  #remove words not in embedding \n",
    "    list_of_embeddings = np.array([embeddings_index[word] for word in tweet_list_filtered],dtype='float64')\n",
    "    return np.mean(list_of_embeddings, axis = 0)\n",
    "\n",
    "def get_Glove_transformation(tweets, dimension):\n",
    "    with open('../Data/embeddings_index.pkl', 'rb') as f:\n",
    "        embeddings_index = pickle.load(f)\n",
    "    x = np.zeros((len(tweets), dimension))\n",
    "    x1 = np.apply_along_axis(Tweet_to_GloVe, 0, tweets, embeddings_index)\n",
    "    # i = 0\n",
    "    # for  tweet in tweets:\n",
    "    #     x[i] = Tweet_to_GloVe(tweet,embeddings_index)\n",
    "    #     i += 1\n",
    "    return x1\n",
    "def SVM_Glove(X_train, X_test, y_train, y_test, number_of_features, display_evaluation = False):\n",
    "    \n",
    "    X_train_glove = get_Glove_transformation(X_train, number_of_features)\n",
    "    X_test_glove = get_Glove_transformation(X_test, number_of_features)\n",
    "    \n",
    "    \n",
    "    clf = svm.SVC()\n",
    "    clf.fit( X_train_glove, y_train)\n",
    "    y_pred = clf.predict(X_test_glove)\n",
    "    \n",
    "    print(\"SVM MODEL with TFIDF transformation \")\n",
    "    print(\"with {} features selected \\n \".format(number_of_features))\n",
    "    print(\"Accuracy:\\n\",get_accuracy(y_test,y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    if (display_evaluation):\n",
    "        evaluate_model(clf,  X_test_glove, y_pred,y_test)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15128/2859787144.py\u001b[0m in \u001b[0;36mSVM_Glove\u001b[1;34m(X_train, X_test, y_train, y_test, number_of_features, display_evaluation)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mSVM_Glove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplay_evaluation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mX_train_glove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_Glove_transformation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mX_test_glove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_Glove_transformation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15128/2859787144.py\u001b[0m in \u001b[0;36mget_Glove_transformation\u001b[1;34m(tweets, dimension)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0membeddings_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdimension\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mx1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_along_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTweet_to_GloVe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membeddings_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;31m# i = 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# for  tweet in tweets:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mapply_along_axis\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\shape_base.py\u001b[0m in \u001b[0;36mapply_along_axis\u001b[1;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m             \u001b[1;34m'Cannot apply_along_axis when any iteration dimensions are 0'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m         ) from None\n\u001b[1;32m--> 379\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minarr_view\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;31m# build a buffer for storing evaluations of func1d.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15128/2859787144.py\u001b[0m in \u001b[0;36mTweet_to_GloVe\u001b[1;34m(tweet, embeddings_index)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mTweet_to_GloVe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0membeddings_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtweet_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtweet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtweet_list_filtered\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#remove words not in embedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mlist_of_embeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0membeddings_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweet_list_filtered\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'float64'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_of_embeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#train\n",
    "\n",
    "SVM_Glove(X_train_clean.tolist(), X_test_clean.tolist(), y_train, y_test, 200)\n",
    "#logistic_regression_TFIDF(X_train_clean, X_test_clean, y_train, y_test, display_evaluation = True,max_features= 30000 , ngram_range=(1,2))\n",
    "#SVM_TFIDF(X_train_clean, X_test_clean, y_train, y_test, max_features = 40000, ngram_range=(1,2) , display_evaluation = False)\n",
    "#naive_bayes_count(X_train_clean, X_test_clean, y_train, y_test, max_features = 10000 , ngram_range =(1,2) , display_evaluation= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
