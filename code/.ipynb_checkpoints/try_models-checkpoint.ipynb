{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed\\anaconda3\\lib\\site-packages\\ekphrasis\\classes\\exmanager.py:14: FutureWarning: Possible nested set at position 42\n",
      "  regexes = {k.lower(): re.compile(self.expressions[k]) for k, v in\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from time import time\n",
    "from helper import *\n",
    "from models import *\n",
    "from cleaning import *\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_set Info: SIZE= 1966637, POSITIVE Tweets =49.57%, NEGATIVE Tweets = 50.43%\n",
      "Test_set Info: SIZE= 491660, POSITIVE Tweets =49.58%, NEGATIVE Tweets = 50.42%\n",
      "1218655\n"
     ]
    }
   ],
   "source": [
    "pos_train , neg_train = load_data(full = True)\n",
    "pos_train = pos_train\n",
    "neg_train = neg_train\n",
    "X_train, X_test, y_train, y_test = split_data(pos_train, neg_train) #return pandas series\n",
    "print(len(pos_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records of positive tweets left 1098912\n",
      "Records of negative tweets left 1133246\n",
      "Wall time: 828 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Drop Duplicates\n",
    "pos_train.drop_duplicates(inplace=True)\n",
    "neg_train.drop_duplicates(inplace=True)\n",
    "print('Records of positive tweets left', len(pos_train))\n",
    "print('Records of negative tweets left', len(neg_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# CELL : avec SVM clean + Train = 15min pour 80.000 train set \n",
    "#clean  \n",
    "X_train_clean= X_train.apply(clean_tweet)\n",
    "X_test_clean = X_test.apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Tweet_to_GloVe(tweet,embeddings_index):\n",
    "    tweet_list = tweet.split()\n",
    "    #tweet_list_filtered =  list(set(tweet_list) & set(embeddings_index.keys()))  #remove words not in embedding \n",
    "    list_of_embeddings = np.array([embeddings_index[word] for word in tweet_list],dtype='float64')\n",
    "    x = np.mean(list_of_embeddings, axis = 0)\n",
    "    #x[np.isinf(x)] = 0 #sanitize infinity\n",
    "    return np.nan_to_num(x)\n",
    "\n",
    "def get_Glove_transformation(tweets, dimension, preprocessed):\n",
    "    if preprocessed:\n",
    "        with open('../Data/preprocessed_embeddings_index.pkl', 'rb') as f:\n",
    "            embeddings_index = pickle.load(f)\n",
    "    else:\n",
    "        with open('../Data/embeddings_index.pkl', 'rb') as f:\n",
    "            embeddings_index = pickle.load(f)     \n",
    "\n",
    "    x = np.zeros((len(tweets), dimension))\n",
    "\n",
    "    for i in tqdm_notebook(range(len(tweets))):\n",
    "        x[i] = Tweet_to_GloVe(tweets[i],embeddings_index)\n",
    "    return x\n",
    "def SVM_Glove(X_train, X_test, y_train, y_test, number_of_features, display_evaluation = False, preprocessed = False):\n",
    "    \n",
    "    X_train_glove = get_Glove_transformation(X_train, number_of_features, preprocessed)\n",
    "    X_test_glove = get_Glove_transformation(X_test, number_of_features, preprocessed)\n",
    "    \n",
    "    with open('../Data/X_train_glove.pkl', 'wb') as f:\n",
    "        pickle.dump(embeddings_index, f)\n",
    "    with open('../Data/X_test_glove.pkl', 'wb') as f:\n",
    "        pickle.dump(embeddings_index, f)\n",
    "    print(\"finished embedding\")\n",
    "    clf = svm.SVC()\n",
    "    clf.fit( X_train_glove, y_train)\n",
    "    y_pred = clf.predict(X_test_glove)\n",
    "    \n",
    "    print(\"SVM MODEL with TFIDF transformation \")\n",
    "    print(\"with {} features selected \\n \".format(number_of_features))\n",
    "    print(\"Accuracy:\\n\",get_accuracy(y_test,y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    if (display_evaluation):\n",
    "        evaluate_model(clf,  X_test_glove, y_pred,y_test)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee4cd08f5704488cb3d85ff03af89e6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1966637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'tweet_list_filtered' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10500/2311546029.py\u001b[0m in \u001b[0;36mSVM_Glove\u001b[1;34m(X_train, X_test, y_train, y_test, number_of_features, display_evaluation, preprocessed)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mSVM_Glove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplay_evaluation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreprocessed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mX_train_glove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_Glove_transformation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreprocessed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0mX_test_glove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_Glove_transformation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreprocessed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10500/2311546029.py\u001b[0m in \u001b[0;36mget_Glove_transformation\u001b[1;34m(tweets, dimension, preprocessed)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTweet_to_GloVe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0membeddings_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mSVM_Glove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplay_evaluation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreprocessed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10500/2311546029.py\u001b[0m in \u001b[0;36mTweet_to_GloVe\u001b[1;34m(tweet, embeddings_index)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mtweet_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtweet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m#tweet_list_filtered =  list(set(tweet_list) & set(embeddings_index.keys()))  #remove words not in embedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mlist_of_embeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0membeddings_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweet_list_filtered\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'float64'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_of_embeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m#x[np.isinf(x)] = 0 #sanitize infinity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tweet_list_filtered' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#train\n",
    "\n",
    "SVM_Glove(X_train_clean.tolist(), X_test_clean.tolist(), y_train, y_test, 25, preprocessed = True)\n",
    "#SVM_Glove(X_train_clean.tolist(), X_test_clean.tolist(), y_train, y_test, 200) 71% with 80000\n",
    "#logistic_regression_TFIDF(X_train_clean, X_test_clean, y_train, y_test, display_evaluation = True,max_features= 30000 , ngram_range=(1,2))\n",
    "#SVM_TFIDF(X_train_clean, X_test_clean, y_train, y_test, max_features = 40000, ngram_range=(1,2) , display_evaluation = False)\n",
    "#naive_bayes_count(X_train_clean, X_test_clean, y_train, y_test, max_features = 10000 , ngram_range =(1,2) , display_evaluation= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
